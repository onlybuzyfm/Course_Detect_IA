{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jose\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jose\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solo una vez al inicio\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.eval()  # No entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        return math.exp(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(text):\n",
    "    probs = [freq / len(text) for freq in Counter(text).values()]\n",
    "    return -sum(p * math.log2(p) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ngram_metrics(text, n=3):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    ngrams = vectorizer.fit_transform([text])\n",
    "    return dict(zip(vectorizer.get_feature_names_out(), ngrams.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def burstiness(text):\n",
    "    words = text.split()\n",
    "    word_counts = Counter(words)\n",
    "    freqs = list(word_counts.values())\n",
    "    if len(freqs) < 2:\n",
    "        return 0.0\n",
    "    return np.std(freqs) / np.mean(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_ngrams(text, n=3, top_k=10):\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n))\n",
    "    ngrams = vectorizer.fit_transform([text])\n",
    "    freqs = ngrams.toarray()[0]\n",
    "    ngram_names = vectorizer.get_feature_names_out()\n",
    "    sorted_ngrams = sorted(zip(ngram_names, freqs), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_ngrams[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_path, extract_to=\"pdfs_temp\"):\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(extract_to):\n",
    "        for f in files:\n",
    "            if f.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, f))\n",
    "    \n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdfs_in_zip(zip_path):\n",
    "    pdf_paths = extract_zip(zip_path)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for path in pdf_paths:\n",
    "        print(f\"Procesando: {os.path.basename(path)}\")\n",
    "        raw = extract_text_from_pdf(path)\n",
    "        clean = preprocess_text(raw)\n",
    "        ent = entropy(clean)\n",
    "        bur = burstiness(clean)\n",
    "        ppl = calculate_perplexity(clean)\n",
    "\n",
    "        results.append({\n",
    "            \"archivo\": os.path.basename(path),\n",
    "            \"entropia\": round(ent, 4),\n",
    "            \"burstiness\": round(bur, 4),\n",
    "            \"perplejidad\": round(ppl, 4)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(zip_path, output_csv=\"resultados.csv\"):\n",
    "    df = process_pdfs_in_zip(zip_path)\n",
    "    \n",
    "    shutil.rmtree(\"pdfs_temp\", ignore_errors=True)\n",
    "    print(\"ðŸ§¹ Carpeta 'pdfs_temp' eliminada.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: D1.pdf\n",
      "Procesando: D2.pdf\n",
      "Procesando: D3.pdf\n",
      "Procesando: D4.pdf\n",
      "Procesando: D5.pdf\n",
      "Procesando: D6.pdf\n",
      "ðŸ§¹ Carpeta 'pdfs_temp' eliminada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archivo</th>\n",
       "      <th>entropia</th>\n",
       "      <th>burstiness</th>\n",
       "      <th>perplejidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1.pdf</td>\n",
       "      <td>4.0744</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>160.4222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2.pdf</td>\n",
       "      <td>4.0528</td>\n",
       "      <td>0.5415</td>\n",
       "      <td>108.0962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3.pdf</td>\n",
       "      <td>3.9881</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>219.6888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4.pdf</td>\n",
       "      <td>4.0383</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>110.8801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5.pdf</td>\n",
       "      <td>4.1078</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>173.1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D6.pdf</td>\n",
       "      <td>4.0451</td>\n",
       "      <td>0.4651</td>\n",
       "      <td>196.9493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  archivo  entropia  burstiness  perplejidad\n",
       "0  D1.pdf    4.0744      0.5679     160.4222\n",
       "1  D2.pdf    4.0528      0.5415     108.0962\n",
       "2  D3.pdf    3.9881      0.6576     219.6888\n",
       "3  D4.pdf    4.0383      0.6880     110.8801\n",
       "4  D5.pdf    4.1078      0.7635     173.1369\n",
       "5  D6.pdf    4.0451      0.4651     196.9493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_resultados = run_pipeline(\"Documents.zip\")\n",
    "\n",
    "display(df_resultados)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
